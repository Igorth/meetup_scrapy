{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspagem de dados com Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Framework para extrair os dados que você quer de algum site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ pip install scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um novo projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ scrapy startproject crowdfunding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ cd crowdfunding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um Spider padrão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/13FPh7EXyAIAJG/giphy.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ scrapy genspider my_spider https://fundrazr.com/find?category=Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Botão NEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find?category=Travel&page=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "npages = 46\n",
    "\n",
    "for i in range(2, npages + 2):\n",
    "    start_urls.append(\"https://fundrazr.com/find?category=Travel&page=\"+str(i)+\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pegando os links da home da campanha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy shell 'https://fundrazr.com/find?category=Travel'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "response.xpath(\"//h2[contains(@class, 'title headline-font')]/a[contains(@class, 'campaign-link')]//@href\").extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(self, response):\n",
    "    for href in response.xpath(\"//h2[contains(@class, 'title headline-font')]/a[contains(@class, 'campaign-link')]//@href\"):\n",
    "        url = \"https:\" + href.extract()\n",
    "        yield scrapy.Request(url, callback=self.parse_dir_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dir_contents(self, response):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com esse esquema de requisições e callbacks que podem gerar novas requisições (com novos callbacks), você pode programar a navegação por um site gerando requisições para os links a serem seguidos, até chegar nas páginas com os itens que nos interessam. Por exemplo, para um spider que precise extrair produtos de um site de compras navegando em páginas por categorias, você poderia usar uma estrutura como a seguinte:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class SkeletonSpider(scrapy.Spider):\n",
    "    name = 'spider-mummy'\n",
    "    start_urls = ['http://www.someonlinewebstore.com']\n",
    "\n",
    "    def parse(self, response):\n",
    "        for c in [...]:\n",
    "            url_category = ...\n",
    "            yield scrapy.Request(url_category, self.parse_category_page)\n",
    "\n",
    "    def parse_category_page(self, response):\n",
    "        for p in [...]:\n",
    "            url_product = ...\n",
    "            yield scrapy.Request(url_product, self.parse_product)\n",
    "\n",
    "    def parse_product(self, response):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pegando as informações interna de cada campanha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item['campaignTitle'] = response.xpath(\"//div[contains(@id, 'campaign-title')]/descendant::text()\").extract()[0].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item['amountRaised'] = response.xpath(\"//span[contains(@class, 'stat')]/span[contains(@class, 'amount-raised')]/descendant::text()\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item['goal'] = \" \".join(response.xpath(\"//div[contains(@class, 'stats-primary with-goal')]//span[contains(@class, 'stats-label hidden-phone')]/text()\").extract()).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currency type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item['currencyType'] = response.xpath(\"//div[contains(@class, 'stats-primary with-goal')]/@title\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item['numberContributors'] = response.xpath(\"//div[contains(@class, 'stats-secondary with-goal')]//span[contains(@class, 'donation-count stat')]/text()\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "story_list = response.xpath(\"//div[contains(@id, 'full-story')]/descendant::text()\").extract()\n",
    "story_list = [x.strip() for x in story_list if len(x.strip()) > 0]\n",
    "item['story']  = \" \".join(story_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "item['url'] = response.xpath(\"//meta[@property='og:url']/@content\").extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrowdfundingItem(scrapy.Item):\n",
    "    # define the fields for your item here like:\n",
    "    # name = scrapy.Field()\n",
    "    campaignTitle = scrapy.Field()\n",
    "    amountRaised = scrapy.Field()\n",
    "    goal = scrapy.Field()\n",
    "    currencyType = scrapy.Field()\n",
    "    numberContributors = scrapy.Field()\n",
    "    story = scrapy.Field()\n",
    "    url = scrapy.Field()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from crowfunding.items import CrowdfundingItem\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_dir_contents(self, response):\n",
    "    item = CrowdfundingItem()\n",
    "\n",
    "    item['campaignTitle'] = response.xpath(\"//div[contains(@id, 'campaign-title')]/descendant::text()\").extract()[0].strip()\n",
    "\n",
    "    item['amountRaised'] = response.xpath(\"//span[contains(@class, 'stat')]/span[contains(@class, 'amount-raised')]/descendant::text()\").extract()\n",
    "\n",
    "    item['goal'] = \" \".join(response.xpath(\"//div[contains(@class, 'stats-primary with-goal')]//span[contains(@class, 'stats-label hidden-phone')]/text()\").extract()).strip()\n",
    "\n",
    "    item['currencyType'] = response.xpath(\"//div[contains(@class, 'stats-primary with-goal')]/@title\").extract()\n",
    "\n",
    "    item['numberContributors'] = response.xpath(\"//div[contains(@class, 'stats-secondary with-goal')]//span[contains(@class, 'donation-count stat')]/text()\").extract()\n",
    "\n",
    "    story_list = response.xpath(\"//div[contains(@id, 'full-story')]/descendant::text()\").extract()\n",
    "    story_list = [x.strip() for x in story_list if len(x.strip()) > 0]\n",
    "    item['story']  = \" \".join(story_list)\n",
    "\n",
    "    item['url'] = response.xpath(\"//meta[@property='og:url']/@content\").extract()\n",
    "\n",
    "    yield item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rodando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy crawl my_scraper -o information.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy crawl my_scraper -o information.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scrapy crawl my_scraper -o information.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd #Para criação de DataFrames\n",
    "import matplotlib.pyplot as plt #Para plotagem\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lê o dataset\n",
    "df = pd.read_csv('information.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>amountRaised</th>\n",
       "      <th>goal</th>\n",
       "      <th>url</th>\n",
       "      <th>campaignTitle</th>\n",
       "      <th>numberContributors</th>\n",
       "      <th>currencyType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are Alice, Brianna, Megan, Paula, and Tabit...</td>\n",
       "      <td>570</td>\n",
       "      <td>of $10k goal</td>\n",
       "      <td>https://fundrazr.com/team-we-live-on-the-road</td>\n",
       "      <td>Team #WeLive Mongol Rally 2016 - On The Road</td>\n",
       "      <td>15.0</td>\n",
       "      <td>U.S. Dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Victoria/Vancouver area is looking to brin...</td>\n",
       "      <td>315</td>\n",
       "      <td>of $500 goal</td>\n",
       "      <td>https://fundrazr.com/e18mV4</td>\n",
       "      <td>Bring Kage to Victoria/Vancouver!</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Canadian Dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hello My name is Slobodan, from Belgrade,Serbi...</td>\n",
       "      <td>170</td>\n",
       "      <td>of €1.5k goal</td>\n",
       "      <td>https://fundrazr.com/d14k7a</td>\n",
       "      <td>Help me visit my grandfathers grave in UK</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Euro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am Wallace Peterson,i m 37 years old with a ...</td>\n",
       "      <td>1,150</td>\n",
       "      <td>of $1.5k goal</td>\n",
       "      <td>https://fundrazr.com/711NYd</td>\n",
       "      <td>Please help us get Wally rolling!</td>\n",
       "      <td>18.0</td>\n",
       "      <td>U.S. Dollar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Mongol Charity Rally July 19th 2015 TEAM: ...</td>\n",
       "      <td>283</td>\n",
       "      <td>of £1k goal</td>\n",
       "      <td>https://fundrazr.com/8s6ca</td>\n",
       "      <td>THE MONGOL CHARITY RALLY 2015 FUNDRAISER</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Pound Sterling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               story amountRaised  \\\n",
       "0  We are Alice, Brianna, Megan, Paula, and Tabit...          570   \n",
       "1  The Victoria/Vancouver area is looking to brin...          315   \n",
       "2  Hello My name is Slobodan, from Belgrade,Serbi...          170   \n",
       "3  I am Wallace Peterson,i m 37 years old with a ...        1,150   \n",
       "4  The Mongol Charity Rally July 19th 2015 TEAM: ...          283   \n",
       "\n",
       "            goal                                            url  \\\n",
       "0   of $10k goal  https://fundrazr.com/team-we-live-on-the-road   \n",
       "1   of $500 goal                    https://fundrazr.com/e18mV4   \n",
       "2  of €1.5k goal                    https://fundrazr.com/d14k7a   \n",
       "3  of $1.5k goal                    https://fundrazr.com/711NYd   \n",
       "4    of £1k goal                     https://fundrazr.com/8s6ca   \n",
       "\n",
       "                                  campaignTitle  numberContributors  \\\n",
       "0  Team #WeLive Mongol Rally 2016 - On The Road                15.0   \n",
       "1             Bring Kage to Victoria/Vancouver!                 4.0   \n",
       "2     Help me visit my grandfathers grave in UK                 3.0   \n",
       "3             Please help us get Wally rolling!                18.0   \n",
       "4      THE MONGOL CHARITY RALLY 2015 FUNDRAISER                10.0   \n",
       "\n",
       "      currencyType  \n",
       "0      U.S. Dollar  \n",
       "1  Canadian Dollar  \n",
       "2             Euro  \n",
       "3      U.S. Dollar  \n",
       "4   Pound Sterling  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostra as 5 primeiras linhas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de linhas e colunas\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
